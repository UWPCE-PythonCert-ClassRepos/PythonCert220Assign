""" This is a parallel program using Mongodb with HP Norton inventory and customer information database functions"""import datetimeimport csvimport osimport loggingfrom threading import Threadfrom pathlib import Pathimport loggingfrom pymongo import MongoClientLOGGER = logging.getLogger()LOGGER.setLevel(logging.INFO)class MongoDBConnection(object):    """MongoDB Connection"""    def __init__(self, host='127.0.0.1', port=27017):        self.host = host        self.port = port        self.connection = None    def __enter__(self):        self.connection = MongoClient(self.host, self.port)        return self    def __exit__(self, exc_type, exc_val, exc_tb):        self.connection.close()def import_data(directory_name, product_file, customer_file, rentals_file,            connection=None, database_name=None):    connection = connection or MongoDBConnection()    database_name = database_name or config.DATABASE_NAME    directory = Path(directory_name)    customer_counts = [0, 0, 0, 0]    product_counts = [0, 0, 0, 0]    customer_counts[1] = database.customers.find().count()    product_counts[1] = database.products.find().count()    a_lock = _thread.allocate_lock()    customer_start = time.time()    with connection:        database = connection.connection.get_database(name=database_name)        #Rentals  and products collection        rentals = database["rentals"]        products = database["products"]        customers = database["customers"]        product_record_count_prior =database.products.find().count()        rental_record_count_prior =database.rentals.find().count()        try:            with open('customers.csv', 'r') as cust_file:                database = connection.connection.get_database(name=database_name)                csvreader = csv.reader(cust_file, delimiter=',', quotechar='|')                customers = customers.split('\n')                customers = filter(None, customers)                customer_record_count = 0 # To count the number of customer records processed (int)                for row in csvreader:                    database.customers.insert_one({'user_id': row[0], 'name': row[1], 'address': row[2], 'zip_code': row[3], 'phone_number': row[4], 'email': row[5]})                    customer_record_count = customer_record_count + 1                    print(f'pid {os.getpid()} Processing customer record {customer_record_count}')                    log_conf.logger.info('* read and load customer csv file to customers collection ')                    customer_counts[0] = customer_record_count                customer_end = time.time()            # time taken to run the customer module (float).            customer_counts[3] = round(customer_end - customer_start, 5)            product_start = time.time()            with open('products.csv', 'r') as prod_file:                csvreader = csv.reader(prod_file, delimiter=',', quotechar='|')                products = products.split('\n')                products  = filter(None, products)                product_record_count = 0 # To count the number of product records processed (int)                for row in csvreader:                    database.products.insert_one({'product_id': row[0], 'description': row[1], 'product_type': row[2], 'quantity_available': row[3]})                product_record_count = product_record_count + 1                print(f'pid {os.getpid()} Processing product record {product_record_count}')                log_conf.logger.info('* read a products csv file and load to products collection ')                product_counts[0] = product_record_count        except IOError:            print('Error: file ', filename, " not found in the current directory.")            quit()        product_end = time.time()        # time taken to run the customer module (float).        product_counts[3] = round(product_end - product_start, 5)        customer_counts[2] =database.customers.find().count()        product_counts[2] =database.products.find().count()        print(f'\ntime taken with linear to add customer = {customer_counts[3]:.5f}s, product = {product_counts[3]:.5f}s csv file to mongodb\n')        return([tuple(customer_counts), tuple(product_counts)])        try:             with concurrent.futures.ThreadPoolExecutor(max_workers=8) as executor:                with concurrent.futures.ThreadPoolExecutor(max_workers=8) as executor:                    executor.submit(customer)                    executor.submit(product)        except Exception as exc:            print('generated an exception: %s' % (exc))            #the customers record count in the database after running (int)            customer_counts[2] = database.customers.find().count()            #the products record count in the database after running (int)            product_counts[2] = database.products.find().count()            print(f'\ntime taken with multithread(parallel) to add customer = {customer_counts[3]:.5f}s, and product {product_counts[3]:.5f}s csv file to mongodb  \n')        return([tuple(customer_counts), tuple(product_counts)])def show_available_products():    customer_info = {}    for rental in database.rentals.find():        if rental["product_id"] == product_id:            customer_info[customer_id] = customer_dict            return customer_infoif __name__ == "__main__":    start = datetime.datetime.now()    #print(import_data(directory_name, product_file, customer_file, rentals_file))    #end_time = time.time()    execute_time = (datetime.datetime.now() - start).total_seconds()    print(f' {execute_time} Total time taken to process in parallel')     # show_available_products()